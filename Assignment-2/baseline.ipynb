{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115ba73d0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/labels.json') as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_line_by_line(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.readlines()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_file_line_by_line('Data/train.txt')\n",
    "val_data = read_file_line_by_line('Data/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "emb_dim = 50\n",
    "with open('glove.6B/glove.6B.50d.txt','r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    embeddings[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab_keys = list(embeddings.keys())\n",
    "full_vocab_keys.append(\"<unk>\")\n",
    "full_vocab = {k: v for v, k in enumerate(full_vocab_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_len = len(full_vocab)\n",
    "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "\n",
    "for i, word in enumerate(full_vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = embeddings[word]\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = torch.from_numpy(weights_matrix).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    sent_labels = []\n",
    "    all_labels = []\n",
    "    sent_idx = []\n",
    "    all_idx = []\n",
    "    for line in (data):\n",
    "        split_line = line.split(\"\\t\")\n",
    "        if len(split_line) == 2:\n",
    "            word = split_line[0]\n",
    "            tag = split_line[1]\n",
    "            tag = tag.replace(\"\\n\", \"\")\n",
    "            word = word.lower()\n",
    "            if word in full_vocab:\n",
    "                sent_idx.append(full_vocab[word])\n",
    "            else:\n",
    "                sent_idx.append(full_vocab[\"<unk>\"])\n",
    "            tag_idx = labels[tag]\n",
    "            sent_labels.append(tag_idx)\n",
    "        elif line==\"\\n\":\n",
    "            sent_idx = np.array(sent_idx)\n",
    "            sent_labels = np.array(sent_labels)\n",
    "            all_idx.append(sent_idx)\n",
    "            all_labels.append(sent_labels)\n",
    "            sent_idx = []\n",
    "            sent_labels = []\n",
    "    return np.asarray(all_idx, dtype=object), np.asarray(all_labels, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = get_data(train_data)\n",
    "valX, valY = get_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_dim, tagset_size):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_dim),\n",
    "                torch.zeros(2, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainX, trainY, valX, valY, epochs):\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    for epoch in (range(epochs)):\n",
    "        print(\"Training Epoch {}\".format(epoch))\n",
    "        for sentence, tags in tqdm(zip(trainX, trainY)):\n",
    "            model.zero_grad()\n",
    "            sentence_in = torch.tensor(sentence)\n",
    "            tag_scores = model(sentence_in)\n",
    "            tags = torch.tensor(tags, dtype=torch.long)\n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        val_loss = 0\n",
    "        for sentence, tags in tqdm(zip(valX, valY)):\n",
    "            sentence_in = torch.tensor(sentence)\n",
    "            tag_scores = model(sentence_in)\n",
    "            tags = torch.tensor(tags, dtype=torch.long)\n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            val_loss += loss.item()\n",
    "        print(\"Validation Loss: {}\".format(val_loss/len(valX)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = BiLSTM(weights_matrix, 64, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 226.41it/s]\n",
      "2267it [00:02, 763.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2738102113406566\n",
      "Training Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 227.90it/s]\n",
      "2267it [00:02, 795.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.157193200200152\n",
      "Training Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 227.26it/s]\n",
      "2267it [00:02, 791.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1458017985937508\n",
      "Training Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 227.70it/s]\n",
      "2267it [00:02, 788.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1423842746043027\n",
      "Training Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 227.94it/s]\n",
      "2267it [00:02, 791.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1404846714728194\n",
      "Training Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 226.45it/s]\n",
      "2267it [00:02, 757.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.138112233607423\n",
      "Training Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 225.56it/s]\n",
      "2267it [00:02, 794.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1360698358361607\n",
      "Training Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 227.79it/s]\n",
      "2267it [00:02, 786.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1345885845339136\n",
      "Training Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 229.29it/s]\n",
      "2267it [00:02, 784.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.133643036115837\n",
      "Training Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7198it [00:31, 228.40it/s]\n",
      "2267it [00:02, 793.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1329308340714586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(ner, trainX, trainY, valX, valY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(valX)):\n",
    "    inp = torch.tensor(valX[i])\n",
    "    out = ner(inp)\n",
    "    # take the argmax of the output\n",
    "    out = out.detach().numpy()\n",
    "    out = np.argmax(out, axis=1)\n",
    "    \n",
    "    gold = valY[i]\n",
    "    correct += np.sum(out == gold)\n",
    "    total += len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.628238662958786"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/total *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
