{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115ba73d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/labels.json') as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_line_by_line(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.readlines()\n",
    "    return text\n",
    "train_data = read_file_line_by_line('Data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data):\n",
    "    vocab = {}\n",
    "    num_words = 0\n",
    "    for line in data:\n",
    "        split_line = line.split(\"\\t\")\n",
    "        if len(split_line) == 2:\n",
    "            word = split_line[0].lower()\n",
    "            if word not in vocab:\n",
    "                vocab[word] = num_words\n",
    "                num_words += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "emb_dim = 50\n",
    "with open('glove.6B/glove.6B.50d.txt','r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    embeddings[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab_keys = list(embeddings.keys())\n",
    "full_vocab_keys.append(\"<unk>\")\n",
    "full_vocab = {k: v for v, k in enumerate(full_vocab_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_len = len(full_vocab)\n",
    "weights_matrix = np.zeros((matrix_len, emb_dim))\n",
    "\n",
    "for i, word in enumerate(full_vocab):\n",
    "    try: \n",
    "        weights_matrix[i] = embeddings[word]\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix = torch.from_numpy(weights_matrix).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    sent_labels = []\n",
    "    all_labels = []\n",
    "    sent_embeddings = []\n",
    "    all_embeddings = []\n",
    "    for line in (data):\n",
    "        split_line = line.split(\"\\t\")\n",
    "        if len(split_line) == 2:\n",
    "            word = split_line[0]\n",
    "            tag = split_line[1]\n",
    "            tag = tag.replace(\"\\n\", \"\")\n",
    "            word = word.lower()\n",
    "            if word in full_vocab:\n",
    "                sent_embeddings.append(full_vocab[word])\n",
    "            else:\n",
    "                sent_embeddings.append(full_vocab[\"<unk>\"])\n",
    "            tag_idx = labels[tag]\n",
    "            sent_labels.append(tag_idx)\n",
    "        elif line==\"\\n\":\n",
    "            sent_embeddings = np.array(sent_embeddings)\n",
    "            sent_labels = np.array(sent_labels)\n",
    "            all_embeddings.append(sent_embeddings)\n",
    "            all_labels.append(sent_labels)\n",
    "            sent_embeddings = []\n",
    "            sent_labels = []\n",
    "    return np.asarray(all_embeddings), np.asarray(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/9kgm8vks4wz6zr8rg0d_pb7w0000gn/T/ipykernel_4895/1899855493.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(all_embeddings), np.asarray(all_labels)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = get_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_dim, tagset_size):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_dim),\n",
    "                torch.zeros(2, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, epochs):\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    for epoch in (range(epochs)):\n",
    "        print(\"Training Epoch {}\".format(epoch))\n",
    "        for sentence, tags in tqdm(zip(train_data, train_labels)):\n",
    "            model.zero_grad()\n",
    "            # convert sentence to tensor\n",
    "            sentence_in = torch.tensor(sentence)\n",
    "            tag_scores = model(sentence_in)\n",
    "            # convert tags to tensor\n",
    "            tags = torch.tensor(tags, dtype=torch.long)\n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # compute loss\n",
    "        print(\"Loss: {}\".format(loss.item()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = BiLSTM(weights_matrix, 64, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "698it [00:03, 228.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[39m=\u001b[39m train_model(ner, trainX, trainY, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [112], line 15\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, train_labels, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(tag_scores, tags)\n\u001b[1;32m     14\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     16\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(loss\u001b[39m.\u001b[39mitem()))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/optim/optimizer.py:139\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m obj, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m    140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/profiler.py:489\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[1;32m    490\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_model(ner, trainX, trainY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/9kgm8vks4wz6zr8rg0d_pb7w0000gn/T/ipykernel_4895/494557449.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(sentence)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 6, 0, 2, 0, 0, 0, 0, 6, 0, 2, 2, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.tensor(trainX[0])\n",
    "out = ner(inp)\n",
    "\n",
    "# take the argmax of the output\n",
    "out = out.detach().numpy()\n",
    "out = np.argmax(out, axis=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/9kgm8vks4wz6zr8rg0d_pb7w0000gn/T/ipykernel_4895/494557449.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(sentence)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(trainX)):\n",
    "    inp = torch.tensor(trainX[i])\n",
    "    out = ner(inp)\n",
    "    # take the argmax of the output\n",
    "    out = out.detach().numpy()\n",
    "    out = np.argmax(out, axis=1)\n",
    "    gold = trainY[i]\n",
    "\n",
    "    correct += np.sum(out == gold)\n",
    "    total += len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.164094958140865"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/total *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
