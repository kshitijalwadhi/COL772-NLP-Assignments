{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from torchcrf import CRF\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/labels.json') as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert the labels\n",
    "labels_inv = {v: k for k, v in labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.readlines()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_file('Data/sample_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "emb_dim = 50\n",
    "with open('glove.6B/glove.6B.50d.txt','r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    embeddings[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read vocab.json\n",
    "with open('vocab.json') as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    sent_idx = []\n",
    "    all_idx = []\n",
    "    for line in (data):\n",
    "        if line != \"\\n\":\n",
    "            word = line.strip()\n",
    "            word = word.lower()\n",
    "            if word in vocab:\n",
    "                sent_idx.append(vocab[word])\n",
    "            else:\n",
    "                sent_idx.append(vocab['<unk>'])\n",
    "        else:\n",
    "            sent_idx = np.array(sent_idx)\n",
    "            all_idx.append(sent_idx)\n",
    "            sent_idx = []\n",
    "    return np.asarray(all_idx, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = get_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(data):\n",
    "    \n",
    "    batch_size = len(data)\n",
    "    \n",
    "    max_len = -1\n",
    "    for i in range(batch_size):\n",
    "        if len(data[i]) > max_len:\n",
    "            max_len = len(data[i])\n",
    "    \n",
    "    seq_lengths = []\n",
    "    for i in range(batch_size):\n",
    "        seq_lengths.append(len(data[i]))\n",
    "    \n",
    "    padded_data = []\n",
    "    mask = []\n",
    "    for i in range(batch_size):\n",
    "        padded_data.append(np.pad(data[i], (0, max_len-len(data[i])), 'constant', constant_values=(vocab[\"<pad>\"])))\n",
    "        mask.append(np.pad(np.ones(len(data[i])), (0, max_len-len(data[i])), 'constant', constant_values=0).astype(bool))\n",
    "    \n",
    "    padded_data = torch.from_numpy(np.array(padded_data))\n",
    "    mask = torch.from_numpy(np.array(mask))\n",
    "\n",
    "    return [padded_data, seq_lengths, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataLoader = DataLoader(testX, batch_size=BATCH_SIZE, shuffle=False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_dim, tagset_size):\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights_matrix, freeze=False)\n",
    "        embedding_dim = weights_matrix.shape[1]\n",
    "        # self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
    "        self.dropout_layer = nn.Dropout(p=0.5)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "        \n",
    "\n",
    "    def forward(self, sentence, labels, mask):\n",
    "        embeds = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = self.dropout_layer(lstm_out)\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        return -self.crf(emissions, labels, mask=mask)\n",
    "\n",
    "    def predict(self, sentence, mask):\n",
    "        embeds = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = self.dropout_layer(lstm_out)\n",
    "        scores = self.hidden2tag(lstm_out)\n",
    "        return self.crf.decode(scores, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMCRF(\n",
       "  (embedding): Embedding(7400, 50)\n",
       "  (lstm): LSTM(50, 256, bidirectional=True)\n",
       "  (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  (hidden2tag): Linear(in_features=512, out_features=38, bias=True)\n",
       "  (crf): CRF(num_tags=38)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for batch in testDataLoader:\n",
    "    X, seq_lens, mask = batch\n",
    "    predictions = model.predict(X, mask)\n",
    "    test_preds.extend(predictions)\n",
    "val_preds = np.array(test_preds, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_preds.txt', 'w') as f:\n",
    "    for i in range(len(test_preds)):\n",
    "        for j in range(len(test_preds[i])):\n",
    "            f.write(labels_inv[test_preds[i][j]] + '\\n')\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
